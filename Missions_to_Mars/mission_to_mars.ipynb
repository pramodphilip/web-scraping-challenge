{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for NASA Mars News Site\n",
    "url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "\n",
    "# Creaters browser window for scraping\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visits url, creates soup object\n",
    "browser.visit(url)\n",
    "soup = BeautifulSoup(browser.html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds news titles, isolates first one\n",
    "titles = soup.find_all('div',class_='content_title')\n",
    "news_title = titles[1].text.strip()\n",
    "news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds paragraph text\n",
    "news_p = soup.find('div',class_='article_teaser_body').text\n",
    "news_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for JPL Featured Space Image, visits site\n",
    "jpl_url = 'https://www.jpl.nasa.gov/images?search=&category=Mars'\n",
    "browser.visit(jpl_url)\n",
    "browser.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates target for browser to click \n",
    "# to page with full sized image\n",
    "target = 'a[class=\"group  cursor-pointer block\"]'\n",
    "browser.find_by_tag(target).click()   \n",
    "\n",
    "#Pauses for a few seconds before grabbing page HTML\n",
    "time.sleep(3)\n",
    "\n",
    "# Grabs html, creates soup object\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "# Finds div tags with full size image urls inside\n",
    "images = soup.find('div',class_=\"lg:w-auto w-full\")\n",
    "\n",
    "# Isolates image url for full size jpeg\n",
    "featured_image_url = images.a['href']\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars Facts URL\n",
    "facts_url = 'https://space-facts.com/mars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads HTML into Pandas Dataframe\n",
    "tables = pd.read_html(facts_url)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs first table and renames columns\n",
    "df = tables[0]\n",
    "df.columns = ['Fact','Value']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts table dataframe back to HTML\n",
    "facts_html = df.to_html()\n",
    "facts_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces \\n in HTML with blanks\n",
    "facts_html.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports HTML to HTML file\n",
    "#df.to_html('mars_facts.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (For MAC OS Users) opens new tab to see mars facts HTML\n",
    "#!open mars_facts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars Hemispheres URL\n",
    "url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visits Mars Hemispheres URL\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishes empty list for dictionaries with\n",
    "# hemisphere information\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Grabs HTML for current page, creates soup object\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs headers for each hemisphere\n",
    "headers = soup.find_all('div', class_=\"description\")\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref = headers[0].h3.text\n",
    "#browser.find_by_text(ref).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#html = browser.html\n",
    "#soup = BeautifulSoup(html,'html.parser')\n",
    "    \n",
    "#titles = soup.find_all('h2', class_=\"title\")\n",
    "#titles[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loops through headers\n",
    "# Pulls the title and img URL for each hemisphere\n",
    "for x in range(len(headers)):\n",
    "    ref = headers[x].h3.text\n",
    "    browser.find_by_text(ref).click()\n",
    "    \n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    \n",
    "    img = soup.find_all('div', class_=\"downloads\")\n",
    "    img_url = img[0].li.a['href']\n",
    "    \n",
    "    titles = soup.find_all('h2',class_=\"title\")\n",
    "    title = titles[0].text\n",
    "    \n",
    "    img_dict = {\"title\":title,\"img_url\":img_url}\n",
    "    hemisphere_image_urls.append(img_dict)\n",
    "    \n",
    "    browser.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
